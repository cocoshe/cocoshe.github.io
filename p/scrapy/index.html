<!DOCTYPE html>
<html lang="en-us">
    <head><meta charset='utf-8'>
<meta name='viewport' content='width=device-width, initial-scale=1'><meta name='description' content='Scrapy Scrapy is written in pure Python and depends on a few key Python packages (among others):
 lxml, an efficient XML and HTML parser parsel, an HTML/XML data extraction library written on top of lxml, w3lib, a multi-purpose helper for dealing with URLs and web page encodings twisted, an asynchronous networking framework cryptography and pyOpenSSL, to deal with various network-level security needs  官方doc
 先scrapy startproject tutorial下好tutorial项目，然后自己配置一下venv进行pip3 install scrapy'><title>Scrapy</title>

<link rel='canonical' href='https://example.com/p/scrapy/'>

<link rel="stylesheet" href="/scss/style.min.css"><meta property='og:title' content='Scrapy'>
<meta property='og:description' content='Scrapy Scrapy is written in pure Python and depends on a few key Python packages (among others):
 lxml, an efficient XML and HTML parser parsel, an HTML/XML data extraction library written on top of lxml, w3lib, a multi-purpose helper for dealing with URLs and web page encodings twisted, an asynchronous networking framework cryptography and pyOpenSSL, to deal with various network-level security needs  官方doc
 先scrapy startproject tutorial下好tutorial项目，然后自己配置一下venv进行pip3 install scrapy'>
<meta property='og:url' content='https://example.com/p/scrapy/'>
<meta property='og:site_name' content='coco&#39;s blog'>
<meta property='og:type' content='article'><meta property='article:section' content='Post' /><meta property='article:published_time' content='2021-11-14T19:32:57&#43;08:00'/><meta property='article:modified_time' content='2021-11-14T19:32:57&#43;08:00'/><meta property='og:image' content='https://example.com/p/scrapy/1.jpg' />
<meta name="twitter:title" content="Scrapy">
<meta name="twitter:description" content="Scrapy Scrapy is written in pure Python and depends on a few key Python packages (among others):
 lxml, an efficient XML and HTML parser parsel, an HTML/XML data extraction library written on top of lxml, w3lib, a multi-purpose helper for dealing with URLs and web page encodings twisted, an asynchronous networking framework cryptography and pyOpenSSL, to deal with various network-level security needs  官方doc
 先scrapy startproject tutorial下好tutorial项目，然后自己配置一下venv进行pip3 install scrapy"><meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:image" content='https://example.com/p/scrapy/1.jpg' />
    <link rel="shortcut icon" href="assets/img/1.png" />

    </head>
    <body class="
    article-page has-toc
">
    <script>
        (function() {
            const colorSchemeKey = 'StackColorScheme';
            if(!localStorage.getItem(colorSchemeKey)){
                localStorage.setItem(colorSchemeKey, "auto");
            }
        })();
    </script><script>
    (function() {
        const colorSchemeKey = 'StackColorScheme';
        const colorSchemeItem = localStorage.getItem(colorSchemeKey);
        const supportDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches === true;

        if (colorSchemeItem == 'dark' || colorSchemeItem === 'auto' && supportDarkMode) {
            

            document.documentElement.dataset.scheme = 'dark';
        } else {
            document.documentElement.dataset.scheme = 'light';
        }
    })();
</script>
<div class="container main-container flex 
    
        extended
    
">
    
        <div id="article-toolbar">
            <a href="/" class="back-home">
                <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-chevron-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <polyline points="15 6 9 12 15 18" />
</svg>



                <span>Back</span>
            </a>
        </div>
    
<main class="main full-width">
    <article class="has-image main-article">
    <header class="article-header">
        <div class="article-image">
            <a href="/p/scrapy/">
                <img src="/p/scrapy/1_hucab7db9daa2d52616108d2452d926035_51257_800x0_resize_q75_box.jpg"
                        srcset="/p/scrapy/1_hucab7db9daa2d52616108d2452d926035_51257_800x0_resize_q75_box.jpg 800w, /p/scrapy/1_hucab7db9daa2d52616108d2452d926035_51257_1600x0_resize_q75_box.jpg 1600w"
                        width="800" 
                        height="450" 
                        loading="lazy"
                        alt="Featured image of post Scrapy" />
                
            </a>
        </div>
    

    <div class="article-details">
    

    <h2 class="article-title">
        <a href="/p/scrapy/">Scrapy</a>
    </h2>

    

    
    <footer class="article-time">
        
            <div>
                <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <path d="M11.795 21h-6.795a2 2 0 0 1 -2 -2v-12a2 2 0 0 1 2 -2h12a2 2 0 0 1 2 2v4" />
  <circle cx="18" cy="18" r="4" />
  <path d="M15 3v4" />
  <path d="M7 3v4" />
  <path d="M3 11h16" />
  <path d="M18 16.496v1.504l1 1" />
</svg>
                <time class="article-time--published">Nov 14, 2021</time>
            </div>
        

        
            <div>
                <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="12" cy="12" r="9" />
  <polyline points="12 7 12 12 15 15" />
</svg>



                <time class="article-time--reading">
                    8 minute read
                </time>
            </div>
        
    </footer>
    
</div>
</header>

    <section class="article-content">
    <h1 id="scrapy">Scrapy</h1>
<p>Scrapy is written in pure Python and depends on a few key Python packages (among others):</p>
<ul>
<li>lxml, an efficient XML and HTML parser</li>
<li>parsel, an HTML/XML data extraction library written on top of lxml,</li>
<li>w3lib, a multi-purpose helper for dealing with URLs and web page encodings</li>
<li>twisted, an asynchronous networking framework</li>
<li>cryptography and pyOpenSSL, to deal with various network-level security needs</li>
</ul>
<p><a class="link" href="https://docs.scrapy.org/en/latest/intro/tutorial.html#creating-a-project"  target="_blank" rel="noopener"
    >官方doc</a></p>
<blockquote>
<p>先<code>scrapy startproject tutorial</code>下好tutorial项目，然后自己配置一下venv进行<code>pip3 install scrapy</code></p>
</blockquote>
<h2 id="get-start">Get start</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">scrapy</span>


<span class="k">class</span> <span class="nc">QuotesSpider</span><span class="p">(</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Spider</span><span class="p">):</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s2">&#34;quotes&#34;</span>

    <span class="k">def</span> <span class="nf">start_requests</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">urls</span> <span class="o">=</span> <span class="p">[</span>
            <span class="s1">&#39;http://quotes.toscrape.com/page/1/&#39;</span><span class="p">,</span>
            <span class="s1">&#39;http://quotes.toscrape.com/page/2/&#39;</span><span class="p">,</span>
        <span class="p">]</span>
        <span class="k">for</span> <span class="n">url</span> <span class="ow">in</span> <span class="n">urls</span><span class="p">:</span>
            <span class="k">yield</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Request</span><span class="p">(</span><span class="n">url</span><span class="o">=</span><span class="n">url</span><span class="p">,</span> <span class="n">callback</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">parse</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="n">page</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">url</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&#34;/&#34;</span><span class="p">)[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span>
        <span class="n">filename</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;quotes-</span><span class="si">{</span><span class="n">page</span><span class="si">}</span><span class="s1">.html&#39;</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="s1">&#39;wb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">body</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Saved file </span><span class="si">{</span><span class="n">filename</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</code></pre></div><blockquote>
<p>主要就是写一个类来继承<code>scrapy.Spider</code>类，然后完成一些必要的属性和方法的实现，如<code>name</code>,<code>start_requests</code>,<code>parse</code>等，都要实现特定的功能</p>
</blockquote>
<p>然后在根目录下运行<code>scrapy crawl quotes</code>得到如下俩html文件</p>
<pre tabindex="0"><code>.
├── bin
├── include
├── lib
├── lib64 -&gt; lib
├── pyvenv.cfg
├── quotes-1.html
├── quotes-2.html
├── scrapy.cfg
├── share
└── tutorial
</code></pre><p><code>start_requests</code>可以用一个<code>start_urls</code>的list来代替，如下：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">scrapy</span>


<span class="k">class</span> <span class="nc">QuotesSpider</span><span class="p">(</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Spider</span><span class="p">):</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s2">&#34;quotes&#34;</span>
    <span class="n">start_urls</span> <span class="o">=</span> <span class="p">[</span>
        <span class="s1">&#39;http://quotes.toscrape.com/page/1/&#39;</span><span class="p">,</span>
        <span class="s1">&#39;http://quotes.toscrape.com/page/2/&#39;</span><span class="p">,</span>
    <span class="p">]</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="n">page</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">url</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&#34;/&#34;</span><span class="p">)[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span>
        <span class="n">filename</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;quotes-</span><span class="si">{</span><span class="n">page</span><span class="si">}</span><span class="s1">.html&#39;</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="s1">&#39;wb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">body</span><span class="p">)</span>
</code></pre></div><p>ps:<code>f'</code>表示之后的字符串可以直接通过大括号<code>{}</code>的方式进行传参~（例如上面的page就是'1',&lsquo;2&rsquo;）</p>
<h2 id="extracting-data">Extracting data</h2>
<p>上面爬到的都是html,接下来要对数据进行提取</p>
<p>下面利用shell进行一些测试</p>
<p>发送请求，并且进入shell</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell">scrapy shell <span class="s1">&#39;http://quotes.toscrape.com/page/1/&#39;</span>
</code></pre></div><p>下面对response中的<code>title</code>进行分析</p>
<ol>
<li>直接取</li>
</ol>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell">&gt;&gt;&gt; response.css<span class="o">(</span><span class="s1">&#39;title&#39;</span><span class="o">)</span>
<span class="o">[</span>&lt;Selector <span class="nv">xpath</span><span class="o">=</span><span class="s1">&#39;descendant-or-self::title&#39;</span> <span class="nv">data</span><span class="o">=</span><span class="s1">&#39;&lt;title&gt;Quotes to Scrape&lt;/title&gt;&#39;</span>&gt;<span class="o">]</span>
</code></pre></div><ol start="2">
<li><code>::text</code>去掉data的<code>&lt;title&gt;</code>标签</li>
</ol>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell">&gt;&gt;&gt; response.css<span class="o">(</span><span class="s1">&#39;title::text&#39;</span><span class="o">)</span>
<span class="o">[</span>&lt;Selector <span class="nv">xpath</span><span class="o">=</span><span class="s1">&#39;descendant-or-self::title/text()&#39;</span> <span class="nv">data</span><span class="o">=</span><span class="s1">&#39;Quotes to Scrape&#39;</span>&gt;<span class="o">]</span>
</code></pre></div><ol start="3">
<li><code>getall()</code>去掉前面的selector</li>
</ol>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell">&gt;&gt;&gt; response.css<span class="o">(</span><span class="s1">&#39;title::text&#39;</span><span class="o">)</span>.getall<span class="o">()</span>
<span class="o">[</span><span class="s1">&#39;Quotes to Scrape&#39;</span><span class="o">]</span>
</code></pre></div><ol start="4">
<li><code>get()</code>得到第一个selector</li>
</ol>
<p>The other thing is that the result of calling <code>.getall()</code> is a list: <strong>it is possible that a selector returns more than one result</strong>, so we extract them all. When you know you just want the first result, as in this case, you can do:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell">&gt;&gt;&gt; response.css<span class="o">(</span><span class="s1">&#39;title::text&#39;</span><span class="o">)</span>.get<span class="o">()</span>
<span class="s1">&#39;Quotes to Scrape&#39;</span>
</code></pre></div><p>或者这样操作</p>
<pre tabindex="0"><code>&gt;&gt;&gt; response.css('title::text')[0].get()
'Quotes to Scrape'
</code></pre><p>但是有缺陷，还是直接用<code>get()</code>好，因为这个可能会下标错误(如果是多个selector的话，用get()是默认返回第0个的)</p>
<blockquote>
<p>Besides the <a class="link" href="https://docs.scrapy.org/en/latest/topics/selectors.html#scrapy.selector.SelectorList.getall"  target="_blank" rel="noopener"
    ><code>getall()</code></a> and <a class="link" href="https://docs.scrapy.org/en/latest/topics/selectors.html#scrapy.selector.SelectorList.get"  target="_blank" rel="noopener"
    ><code>get()</code></a> methods, you can also use the <a class="link" href="https://docs.scrapy.org/en/latest/topics/selectors.html#scrapy.selector.SelectorList.re"  target="_blank" rel="noopener"
    ><code>re()</code></a> method to extract using</p>
<p>除了<code>getall</code>、<code>get</code>等方法，还有一个<code>re()</code>方法可以根据正则表达式提取想要的数据</p>
</blockquote>
<p>example:</p>
<p>对一个名人名言网站进行爬取，先请求一下得到response等信息</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell">scrapy shell <span class="s1">&#39;http://quotes.toscrape.com&#39;</span>
</code></pre></div><p>爬到的html大概是这样的(对于第一句话)</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-html" data-lang="html"><span class="p">&lt;</span><span class="nt">div</span> <span class="na">class</span><span class="o">=</span><span class="s">&#34;quote&#34;</span><span class="p">&gt;</span>
    <span class="p">&lt;</span><span class="nt">span</span> <span class="na">class</span><span class="o">=</span><span class="s">&#34;text&#34;</span><span class="p">&gt;</span>“The world as we have created it is a process of our
    thinking. It cannot be changed without changing our thinking.”<span class="p">&lt;/</span><span class="nt">span</span><span class="p">&gt;</span>
    <span class="p">&lt;</span><span class="nt">span</span><span class="p">&gt;</span>
        by <span class="p">&lt;</span><span class="nt">small</span> <span class="na">class</span><span class="o">=</span><span class="s">&#34;author&#34;</span><span class="p">&gt;</span>Albert Einstein<span class="p">&lt;/</span><span class="nt">small</span><span class="p">&gt;</span>
        <span class="p">&lt;</span><span class="nt">a</span> <span class="na">href</span><span class="o">=</span><span class="s">&#34;/author/Albert-Einstein&#34;</span><span class="p">&gt;</span>(about)<span class="p">&lt;/</span><span class="nt">a</span><span class="p">&gt;</span>
    <span class="p">&lt;/</span><span class="nt">span</span><span class="p">&gt;</span>
    <span class="p">&lt;</span><span class="nt">div</span> <span class="na">class</span><span class="o">=</span><span class="s">&#34;tags&#34;</span><span class="p">&gt;</span>
        Tags:
        <span class="p">&lt;</span><span class="nt">a</span> <span class="na">class</span><span class="o">=</span><span class="s">&#34;tag&#34;</span> <span class="na">href</span><span class="o">=</span><span class="s">&#34;/tag/change/page/1/&#34;</span><span class="p">&gt;</span>change<span class="p">&lt;/</span><span class="nt">a</span><span class="p">&gt;</span>
        <span class="p">&lt;</span><span class="nt">a</span> <span class="na">class</span><span class="o">=</span><span class="s">&#34;tag&#34;</span> <span class="na">href</span><span class="o">=</span><span class="s">&#34;/tag/deep-thoughts/page/1/&#34;</span><span class="p">&gt;</span>deep-thoughts<span class="p">&lt;/</span><span class="nt">a</span><span class="p">&gt;</span>
        <span class="p">&lt;</span><span class="nt">a</span> <span class="na">class</span><span class="o">=</span><span class="s">&#34;tag&#34;</span> <span class="na">href</span><span class="o">=</span><span class="s">&#34;/tag/thinking/page/1/&#34;</span><span class="p">&gt;</span>thinking<span class="p">&lt;/</span><span class="nt">a</span><span class="p">&gt;</span>
        <span class="p">&lt;</span><span class="nt">a</span> <span class="na">class</span><span class="o">=</span><span class="s">&#34;tag&#34;</span> <span class="na">href</span><span class="o">=</span><span class="s">&#34;/tag/world/page/1/&#34;</span><span class="p">&gt;</span>world<span class="p">&lt;/</span><span class="nt">a</span><span class="p">&gt;</span>
    <span class="p">&lt;/</span><span class="nt">div</span><span class="p">&gt;</span>
<span class="p">&lt;/</span><span class="nt">div</span><span class="p">&gt;</span>
</code></pre></div><p>通过response的css方法访问div标签且class为&quot;quote&quot;的部分，返回的应该是一个列表，因为每句话都是这样的形式，上面只是其中的一句话。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-powershell" data-lang="powershell"><span class="n">response</span><span class="p">.</span><span class="n">css</span><span class="p">(</span><span class="s2">&#34;div.quote&#34;</span><span class="p">)</span>
<span class="p">[&lt;</span><span class="n">Selector</span> <span class="n">xpath</span><span class="p">=</span><span class="s2">&#34;descendant-or-self::div[@class and contains(concat(&#39; &#39;, normalize-space(@class), &#39; &#39;), &#39; quote &#39;)]&#34;</span> <span class="n">data</span><span class="p">=</span><span class="s1">&#39;&lt;div class=&#34;quote&#34; itemscope itemtype...&#39;</span><span class="p">&gt;,</span>
 <span class="p">&lt;</span><span class="n">Selector</span> <span class="n">xpath</span><span class="p">=</span><span class="s2">&#34;descendant-or-self::div[@class and contains(concat(&#39; &#39;, normalize-space(@class), &#39; &#39;), &#39; quote &#39;)]&#34;</span> <span class="n">data</span><span class="p">=</span><span class="s1">&#39;&lt;div class=&#34;quote&#34; itemscope itemtype...&#39;</span><span class="p">&gt;,</span>
 <span class="p">...]</span>
</code></pre></div><p>可以选择第一句</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="nv">quote</span> <span class="o">=</span> response.css<span class="o">(</span><span class="s2">&#34;div.quote&#34;</span><span class="o">)[</span>0<span class="o">]</span>
</code></pre></div><p>接着可以进行提取</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="nv">text</span> <span class="o">=</span> quote.css<span class="o">(</span><span class="s2">&#34;span.text::text&#34;</span><span class="o">)</span>.get<span class="o">()</span>
&gt;&gt;&gt; text
<span class="s1">&#39;“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”&#39;</span>
&gt;&gt;&gt; <span class="nv">author</span> <span class="o">=</span> quote.css<span class="o">(</span><span class="s2">&#34;small.author::text&#34;</span><span class="o">)</span>.get<span class="o">()</span>
&gt;&gt;&gt; author
<span class="s1">&#39;Albert Einstein&#39;</span>
</code></pre></div><p>获得tags下面的所有tag</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="nv">tags</span> <span class="o">=</span> quote.css<span class="o">(</span><span class="s2">&#34;div.tags a.tag::text&#34;</span><span class="o">)</span>.getall<span class="o">()</span>
&gt;&gt;&gt; tags
<span class="o">[</span><span class="s1">&#39;change&#39;</span>, <span class="s1">&#39;deep-thoughts&#39;</span>, <span class="s1">&#39;thinking&#39;</span>, <span class="s1">&#39;world&#39;</span><span class="o">]</span>
</code></pre></div><p>上面尝试完了shell中的运行，接下来可以试着把写一个脚本来实现</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="k">for</span> <span class="n">quote</span> <span class="ow">in</span> <span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s2">&#34;div.quote&#34;</span><span class="p">):</span>
<span class="o">...</span>     <span class="n">text</span> <span class="o">=</span> <span class="n">quote</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s2">&#34;span.text::text&#34;</span><span class="p">)</span><span class="o">.</span><span class="n">get</span><span class="p">()</span>
<span class="o">...</span>     <span class="n">author</span> <span class="o">=</span> <span class="n">quote</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s2">&#34;small.author::text&#34;</span><span class="p">)</span><span class="o">.</span><span class="n">get</span><span class="p">()</span>
<span class="o">...</span>     <span class="n">tags</span> <span class="o">=</span> <span class="n">quote</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s2">&#34;div.tags a.tag::text&#34;</span><span class="p">)</span><span class="o">.</span><span class="n">getall</span><span class="p">()</span>
<span class="o">...</span>     <span class="nb">print</span><span class="p">(</span><span class="nb">dict</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="n">text</span><span class="p">,</span> <span class="n">author</span><span class="o">=</span><span class="n">author</span><span class="p">,</span> <span class="n">tags</span><span class="o">=</span><span class="n">tags</span><span class="p">))</span>
<span class="p">{</span><span class="s1">&#39;text&#39;</span><span class="p">:</span> <span class="s1">&#39;“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”&#39;</span><span class="p">,</span> <span class="s1">&#39;author&#39;</span><span class="p">:</span> <span class="s1">&#39;Albert Einstein&#39;</span><span class="p">,</span> <span class="s1">&#39;tags&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;change&#39;</span><span class="p">,</span> <span class="s1">&#39;deep-thoughts&#39;</span><span class="p">,</span> <span class="s1">&#39;thinking&#39;</span><span class="p">,</span> <span class="s1">&#39;world&#39;</span><span class="p">]}</span>
<span class="p">{</span><span class="s1">&#39;text&#39;</span><span class="p">:</span> <span class="s1">&#39;“It is our choices, Harry, that show what we truly are, far more than our abilities.”&#39;</span><span class="p">,</span> <span class="s1">&#39;author&#39;</span><span class="p">:</span> <span class="s1">&#39;J.K. Rowling&#39;</span><span class="p">,</span> <span class="s1">&#39;tags&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;abilities&#39;</span><span class="p">,</span> <span class="s1">&#39;choices&#39;</span><span class="p">]}</span>
<span class="o">...</span>
</code></pre></div><p>循环实现所有的quote的爬取</p>
<p>回到我们之前最早的例程中，改写如下：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">scrapy</span>


<span class="k">class</span> <span class="nc">QuotesSpider</span><span class="p">(</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Spider</span><span class="p">):</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s2">&#34;quotes&#34;</span>
    <span class="n">start_urls</span> <span class="o">=</span> <span class="p">[</span>
        <span class="s1">&#39;http://quotes.toscrape.com/page/1/&#39;</span><span class="p">,</span>
        <span class="s1">&#39;http://quotes.toscrape.com/page/2/&#39;</span><span class="p">,</span>
    <span class="p">]</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">quote</span> <span class="ow">in</span> <span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">&#39;div.quote&#39;</span><span class="p">):</span>
            <span class="k">yield</span> <span class="p">{</span>
                <span class="s1">&#39;text&#39;</span><span class="p">:</span> <span class="n">quote</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">&#39;span.text::text&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">get</span><span class="p">(),</span>
                <span class="s1">&#39;author&#39;</span><span class="p">:</span> <span class="n">quote</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">&#39;small.author::text&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">get</span><span class="p">(),</span>
                <span class="s1">&#39;tags&#39;</span><span class="p">:</span> <span class="n">quote</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">&#39;div.tags a.tag::text&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">getall</span><span class="p">(),</span>
            <span class="p">}</span>
</code></pre></div><p>正如官方文档写的那样：</p>
<p>If you run this spider, it will output the extracted data with the log:</p>
<pre tabindex="0"><code>2016-09-19 18:57:19 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 http://quotes.toscrape.com/page/1/&gt;
{'tags': ['life', 'love'], 'author': 'André Gide', 'text': '“It is better to be hated for what you are than to be loved for what you are not.”'}
2016-09-19 18:57:19 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 http://quotes.toscrape.com/page/1/&gt;
{'tags': ['edison', 'failure', 'inspirational', 'paraphrased'], 'author': 'Thomas A. Edison', 'text': &quot;“I have not failed. I've just found 10,000 ways that won't work.”&quot;}
</code></pre><h2 id="storing-the-scraped-data">Storing the scraped data</h2>
<p>最简单的方法是用<a class="link" href="https://docs.scrapy.org/en/latest/topics/feed-exports.html#topics-feed-exports"  target="_blank" rel="noopener"
    >Feed exports</a>，例如json、json line、xml、csv等</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell">scrapy crawl quotes -O quotes.json
</code></pre></div><p>That will generate a <code>quotes.json</code> file containing all scraped items, serialized in <a class="link" href="https://en.wikipedia.org/wiki/JSON"  target="_blank" rel="noopener"
    >JSON</a>.</p>
<p>The <code>-O</code> command-line switch overwrites any existing file; use <code>-o</code> instead to append new content to any existing file**(个人感觉是json外层有一对中括号的缘故，而json line没有，而是&quot;流式&quot;的)**.However, appending to a JSON file makes the file contents invalid JSON. When appending to a file, consider using a different serialization format, such as <a class="link" href="http://jsonlines.org/"  target="_blank" rel="noopener"
    >JSON Lines</a>:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell">scrapy crawl quotes -o quotes.jl
</code></pre></div><h2 id="following-links">Following links</h2>
<p>Q：当你不满足于当前页的爬取，想要利用nextpage按钮来跳转到下一页进行自动爬取的时候该怎么办？</p>
<p>观察到跳转按键如下</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-html" data-lang="html"><span class="p">&lt;</span><span class="nt">ul</span> <span class="na">class</span><span class="o">=</span><span class="s">&#34;pager&#34;</span><span class="p">&gt;</span>
    <span class="p">&lt;</span><span class="nt">li</span> <span class="na">class</span><span class="o">=</span><span class="s">&#34;next&#34;</span><span class="p">&gt;</span>
        <span class="p">&lt;</span><span class="nt">a</span> <span class="na">href</span><span class="o">=</span><span class="s">&#34;/page/2/&#34;</span><span class="p">&gt;</span>Next <span class="p">&lt;</span><span class="nt">span</span> <span class="na">aria-hidden</span><span class="o">=</span><span class="s">&#34;true&#34;</span><span class="p">&gt;</span><span class="ni">&amp;rarr;</span><span class="p">&lt;/</span><span class="nt">span</span><span class="p">&gt;&lt;/</span><span class="nt">a</span><span class="p">&gt;</span>
    <span class="p">&lt;/</span><span class="nt">li</span><span class="p">&gt;</span>
<span class="p">&lt;/</span><span class="nt">ul</span><span class="p">&gt;</span>
</code></pre></div><p>我们在shell中输入下面的命令</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell">response.css<span class="o">(</span><span class="s1">&#39;li.next a&#39;</span><span class="o">)</span>.get<span class="o">()</span>
<span class="s1">&#39;&lt;a href=&#34;/page/2/&#34;&gt;Next &lt;span aria-hidden=&#34;true&#34;&gt;→&lt;/span&gt;&lt;/a&gt;&#39;</span>
</code></pre></div><p>This gets the anchor element, but we want the attribute <code>href</code>. For that, Scrapy supports a CSS extension that lets you select the attribute contents, like this:</p>
<pre tabindex="0"><code>&gt;&gt;&gt; response.css('li.next a::attr(href)').get()
'/page/2/'
</code></pre><p>There is also an <code>attrib</code> property available (see <a class="link" href="https://docs.scrapy.org/en/latest/topics/selectors.html#selecting-attributes"  target="_blank" rel="noopener"
    >Selecting element attributes</a> for more):</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell">&gt;&gt;&gt; response.css<span class="o">(</span><span class="s1">&#39;li.next a&#39;</span><span class="o">)</span>.attrib<span class="o">[</span><span class="s1">&#39;href&#39;</span><span class="o">]</span>
<span class="s1">&#39;/page/2/&#39;</span>
</code></pre></div><p>Let’s see now our spider modified to recursively follow the link to the next page, extracting data from it:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">scrapy</span>


<span class="k">class</span> <span class="nc">QuotesSpider</span><span class="p">(</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Spider</span><span class="p">):</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s2">&#34;quotes&#34;</span>
    <span class="n">start_urls</span> <span class="o">=</span> <span class="p">[</span>
        <span class="s1">&#39;http://quotes.toscrape.com/page/1/&#39;</span><span class="p">,</span>
    <span class="p">]</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">quote</span> <span class="ow">in</span> <span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">&#39;div.quote&#39;</span><span class="p">):</span>
            <span class="k">yield</span> <span class="p">{</span>
                <span class="s1">&#39;text&#39;</span><span class="p">:</span> <span class="n">quote</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">&#39;span.text::text&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">get</span><span class="p">(),</span>
                <span class="s1">&#39;author&#39;</span><span class="p">:</span> <span class="n">quote</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">&#39;small.author::text&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">get</span><span class="p">(),</span>
                <span class="s1">&#39;tags&#39;</span><span class="p">:</span> <span class="n">quote</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">&#39;div.tags a.tag::text&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">getall</span><span class="p">(),</span>
            <span class="p">}</span>

        <span class="n">next_page</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">&#39;li.next a::attr(href)&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">get</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">next_page</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">next_page</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">urljoin</span><span class="p">(</span><span class="n">next_page</span><span class="p">)</span>
            <span class="k">yield</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Request</span><span class="p">(</span><span class="n">next_page</span><span class="p">,</span> <span class="n">callback</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">parse</span><span class="p">)</span>
</code></pre></div><p>通过urljoin的方式进行url的拼接，然后得到下一页，利用回调函数慢慢一页页搞下去</p>
<p><strong>对于<code>urljoin</code>的个人理解：不是普通的拼接，他应该会根据原来url中的'/&lsquo;和next_page中的url的&rsquo;/&lsquo;进行对比，从后往前根据&rsquo;/&lsquo;去匹配到一个合适的位置进行替换</strong></p>
<h2 id="a-shortcut-for-creating-requests">A shortcut for creating Requests</h2>
<p>利用<a class="link" href="https://docs.scrapy.org/en/latest/topics/request-response.html#scrapy.http.TextResponse.follow"  target="_blank" rel="noopener"
    ><code>response.follow</code></a>来代替<code>scrapy.Request</code></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">scrapy</span>


<span class="k">class</span> <span class="nc">QuotesSpider</span><span class="p">(</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Spider</span><span class="p">):</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s2">&#34;quotes&#34;</span>
    <span class="n">start_urls</span> <span class="o">=</span> <span class="p">[</span>
        <span class="s1">&#39;http://quotes.toscrape.com/page/1/&#39;</span><span class="p">,</span>
    <span class="p">]</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">quote</span> <span class="ow">in</span> <span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">&#39;div.quote&#39;</span><span class="p">):</span>
            <span class="k">yield</span> <span class="p">{</span>
                <span class="s1">&#39;text&#39;</span><span class="p">:</span> <span class="n">quote</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">&#39;span.text::text&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">get</span><span class="p">(),</span>
                <span class="s1">&#39;author&#39;</span><span class="p">:</span> <span class="n">quote</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">&#39;span small::text&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">get</span><span class="p">(),</span>
                <span class="s1">&#39;tags&#39;</span><span class="p">:</span> <span class="n">quote</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">&#39;div.tags a.tag::text&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">getall</span><span class="p">(),</span>
            <span class="p">}</span>

        <span class="n">next_page</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">&#39;li.next a::attr(href)&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">get</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">next_page</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">yield</span> <span class="n">response</span><span class="o">.</span><span class="n">follow</span><span class="p">(</span><span class="n">next_page</span><span class="p">,</span> <span class="n">callback</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">parse</span><span class="p">)</span>
</code></pre></div><p>对比两种方法，前者省略了<code>urljoin</code>的过程：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python">        <span class="k">if</span> <span class="n">next_page</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">yield</span> <span class="n">response</span><span class="o">.</span><span class="n">follow</span><span class="p">(</span><span class="n">next_page</span><span class="p">,</span> <span class="n">callback</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">parse</span><span class="p">)</span>
</code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python">        <span class="k">if</span> <span class="n">next_page</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">next_page</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">urljoin</span><span class="p">(</span><span class="n">next_page</span><span class="p">)</span>
            <span class="k">yield</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Request</span><span class="p">(</span><span class="n">next_page</span><span class="p">,</span> <span class="n">callback</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">parse</span><span class="p">)</span>
</code></pre></div><p>You can also pass a selector to <code>response.follow</code> instead of a string; this selector should extract necessary attributes:</p>
<pre tabindex="0"><code>for href in response.css('ul.pager a::attr(href)'):
    yield response.follow(href, callback=self.parse)
</code></pre><p>For <code>&lt;a&gt;</code> elements there is a shortcut: <code>response.follow</code> uses their href attribute automatically. So the code can be shortened further:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">&#39;ul.pager a&#39;</span><span class="p">):</span>
    <span class="k">yield</span> <span class="n">response</span><span class="o">.</span><span class="n">follow</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">callback</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">parse</span><span class="p">)</span>
</code></pre></div><p>To create multiple requests from an iterable, you can use <a class="link" href="https://docs.scrapy.org/en/latest/topics/request-response.html#scrapy.http.TextResponse.follow_all"  target="_blank" rel="noopener"
    ><code>response.follow_all</code></a> instead:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="n">anchors</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">&#39;ul.pager a&#39;</span><span class="p">)</span>
<span class="k">yield from</span> <span class="n">response</span><span class="o">.</span><span class="n">follow_all</span><span class="p">(</span><span class="n">anchors</span><span class="p">,</span> <span class="n">callback</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">parse</span><span class="p">)</span>
</code></pre></div><p>or, shortening it further:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="k">yield from</span> <span class="n">response</span><span class="o">.</span><span class="n">follow_all</span><span class="p">(</span><span class="n">css</span><span class="o">=</span><span class="s1">&#39;ul.pager a&#39;</span><span class="p">,</span> <span class="n">callback</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">parse</span><span class="p">)</span>
</code></pre></div><h2 id="more-examples-and-patterns">More examples and patterns</h2>
<blockquote>
<p>一堆<del>懒狗</del>精简用法，主要是用了一次就<code>yield</code>一下把数据扔了，直接看吧不解释了<del>主要是懒</del></p>
</blockquote>
<p>Here is another spider that illustrates callbacks and following links, this time for scraping author information:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">scrapy</span>


<span class="k">class</span> <span class="nc">AuthorSpider</span><span class="p">(</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Spider</span><span class="p">):</span>
    <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;author&#39;</span>

    <span class="n">start_urls</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;http://quotes.toscrape.com/&#39;</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="n">author_page_links</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">&#39;.author + a&#39;</span><span class="p">)</span>
        <span class="k">yield from</span> <span class="n">response</span><span class="o">.</span><span class="n">follow_all</span><span class="p">(</span><span class="n">author_page_links</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">parse_author</span><span class="p">)</span>

        <span class="n">pagination_links</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="s1">&#39;li.next a&#39;</span><span class="p">)</span>
        <span class="k">yield from</span> <span class="n">response</span><span class="o">.</span><span class="n">follow_all</span><span class="p">(</span><span class="n">pagination_links</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">parse</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">parse_author</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
        <span class="k">def</span> <span class="nf">extract_with_css</span><span class="p">(</span><span class="n">query</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">response</span><span class="o">.</span><span class="n">css</span><span class="p">(</span><span class="n">query</span><span class="p">)</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>

        <span class="k">yield</span> <span class="p">{</span>
            <span class="s1">&#39;name&#39;</span><span class="p">:</span> <span class="n">extract_with_css</span><span class="p">(</span><span class="s1">&#39;h3.author-title::text&#39;</span><span class="p">),</span>
            <span class="s1">&#39;birthdate&#39;</span><span class="p">:</span> <span class="n">extract_with_css</span><span class="p">(</span><span class="s1">&#39;.author-born-date::text&#39;</span><span class="p">),</span>
            <span class="s1">&#39;bio&#39;</span><span class="p">:</span> <span class="n">extract_with_css</span><span class="p">(</span><span class="s1">&#39;.author-description::text&#39;</span><span class="p">),</span>
        <span class="p">}</span>
</code></pre></div><p>This spider will start from the main page, it will follow all the links to the authors pages calling the <code>parse_author</code> callback for each of them, and also the pagination links with the <code>parse</code> callback as we saw before.</p>
<p>Here we’re passing callbacks to <a class="link" href="https://docs.scrapy.org/en/latest/topics/request-response.html#scrapy.http.TextResponse.follow_all"  target="_blank" rel="noopener"
    ><code>response.follow_all</code></a> as positional arguments to make the code shorter; it also works for <a class="link" href="https://docs.scrapy.org/en/latest/topics/request-response.html#scrapy.http.Request"  target="_blank" rel="noopener"
    ><code>Request</code></a>.</p>
<p>The <code>parse_author</code> callback defines a helper function to extract and cleanup the data from a CSS query and yields the Python dict with the author data.</p>
<p>Another interesting thing this spider demonstrates is that, even if there are many quotes from the same author, we don’t need to worry about visiting the same author page multiple times. By default, Scrapy filters out duplicated requests to URLs already visited, avoiding the problem of hitting servers too much because of a programming mistake. This can be configured by the setting <a class="link" href="https://docs.scrapy.org/en/latest/topics/settings.html#std-setting-DUPEFILTER_CLASS"  target="_blank" rel="noopener"
    ><code>DUPEFILTER_CLASS</code></a>.</p>
<p>Hopefully by now you have a good understanding of how to use the mechanism of following links and callbacks with Scrapy.</p>
<p>As yet another example spider that leverages the mechanism of following links, check out the <a class="link" href="https://docs.scrapy.org/en/latest/topics/spiders.html#scrapy.spiders.CrawlSpider"  target="_blank" rel="noopener"
    ><code>CrawlSpider</code></a> class for a generic spider that implements a small rules engine that you can use to write your crawlers on top of it.</p>
<p>Also, a common pattern is to build an item with data from more than one page, using a <a class="link" href="https://docs.scrapy.org/en/latest/topics/request-response.html#topics-request-response-ref-request-callback-arguments"  target="_blank" rel="noopener"
    >trick to pass additional data to the callbacks</a>.</p>
<h2 id="using-spider-arguments">Using spider arguments</h2>
<p>You can provide command line arguments to your spiders by using the <code>-a</code> option when running them:</p>
<pre tabindex="0"><code>scrapy crawl quotes -O quotes-humor.json -a tag=humor
</code></pre><p>These arguments are passed to the Spider’s <code>__init__</code> method and become spider attributes by default.</p>
<p>In this example, the value provided for the <code>tag</code> argument will be available via <code>self.tag</code>. You can use this to make your spider fetch only quotes with a specific tag, building the URL based on the argument:</p>
<pre tabindex="0"><code>import scrapy


class QuotesSpider(scrapy.Spider):
    name = &quot;quotes&quot;

    def start_requests(self):
        url = 'http://quotes.toscrape.com/'
        tag = getattr(self, 'tag', None)
        if tag is not None:
            url = url + 'tag/' + tag
        yield scrapy.Request(url, self.parse)

    def parse(self, response):
        for quote in response.css('div.quote'):
            yield {
                'text': quote.css('span.text::text').get(),
                'author': quote.css('small.author::text').get(),
            }

        next_page = response.css('li.next a::attr(href)').get()
        if next_page is not None:
            yield response.follow(next_page, self.parse)
</code></pre><p>If you pass the <code>tag=humor</code> argument to this spider, you’ll notice that it will only visit URLs from the <code>humor</code> tag, such as <code>http://quotes.toscrape.com/tag/humor</code>.</p>
<p>You can <a class="link" href="https://docs.scrapy.org/en/latest/topics/spiders.html#spiderargs"  target="_blank" rel="noopener"
    >learn more about handling spider arguments here</a>.</p>
<h2 id="next-steps">Next steps</h2>
<p>This tutorial covered only the basics of Scrapy, but there’s a lot of other features not mentioned here. Check the <a class="link" href="https://docs.scrapy.org/en/latest/intro/overview.html#topics-whatelse"  target="_blank" rel="noopener"
    >What else?</a> section in <a class="link" href="https://docs.scrapy.org/en/latest/intro/overview.html#intro-overview"  target="_blank" rel="noopener"
    >Scrapy at a glance</a> chapter for a quick overview of the most important ones.</p>
<p>You can continue from the section <a class="link" href="https://docs.scrapy.org/en/latest/index.html#section-basics"  target="_blank" rel="noopener"
    >Basic concepts</a> to know more about the command-line tool, spiders, selectors and other things the tutorial hasn’t covered like modeling the scraped data. If you prefer to play with an example project, check the <a class="link" href="https://docs.scrapy.org/en/latest/intro/examples.html#intro-examples"  target="_blank" rel="noopener"
    >Examples</a> section.</p>

</section>


    <footer class="article-footer">
    

    
    <section class="article-copyright">
        <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-copyright" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="12" cy="12" r="9" />
  <path d="M14.5 9a3.5 4 0 1 0 0 6" />
</svg>



        <span>Licensed under CC BY-NC-SA 4.0</span>
    </section>
    </footer>


    
</article>

    <aside class="related-contents--wrapper">
    
    
</aside>

     
    
        
    <div class="disqus-container">
    <div id="disqus_thread"></div>
<script type="application/javascript">
    var disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "hugo-theme-stack" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
</div>

<style>
    .disqus-container {
        background-color: var(--card-background);
        border-radius: var(--card-border-radius);
        box-shadow: var(--shadow-l1);
        padding: var(--card-padding);
    }
</style>

<script>
    window.addEventListener('onColorSchemeChange', (e) => {
        if (DISQUS) {
            DISQUS.reset({
                reload: true
            });
        }
    })
</script>

    

    <footer class="site-footer">
    <section class="copyright">
        &copy; 
        
            2020 - 
        
        2021 coco&#39;s blog
    </section>
    
    <section class="powerby">
        Built with <a href="https://gohugo.io/" target="_blank" rel="noopener">Hugo</a> <br />
        Theme <b><a href="https://github.com/CaiJimmy/hugo-theme-stack" target="_blank" rel="noopener" data-version="3.5.0">Stack</a></b> designed by <a href="https://jimmycai.com" target="_blank" rel="noopener">Jimmy</a>
    </section>
</footer>


    
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    
    <div class="pswp__bg"></div>

    
    <div class="pswp__scroll-wrap">

        
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                
                
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                        <div class="pswp__preloader__cut">
                            <div class="pswp__preloader__donut"></div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div><script 
                src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js"integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo="crossorigin="anonymous"
                defer="true"
                >
            </script><script 
                src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js"integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU="crossorigin="anonymous"
                defer="true"
                >
            </script><link 
                rel="stylesheet" 
                href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.css"integrity="sha256-c0uckgykQ9v5k&#43;IqViZOZKc47Jn7KQil4/MP3ySA3F8="crossorigin="anonymous"
            ><link 
                rel="stylesheet" 
                href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.css"integrity="sha256-SBLU4vv6CA6lHsZ1XyTdhyjJxCjPif/TRkjnsyGAGnE="crossorigin="anonymous"
            >

            </main>
    
        <aside class="sidebar right-sidebar sticky">
            <section class="widget archives">
                <div class="widget-icon">
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <line x1="5" y1="9" x2="19" y2="9" />
  <line x1="5" y1="15" x2="19" y2="15" />
  <line x1="11" y1="4" x2="7" y2="20" />
  <line x1="17" y1="4" x2="13" y2="20" />
</svg>



                </div>
                <h2 class="widget-title section-title">Table of contents</h2>
                
                <div class="widget--toc">
                    <nav id="TableOfContents">
  <ol>
    <li><a href="#get-start">Get start</a></li>
    <li><a href="#extracting-data">Extracting data</a></li>
    <li><a href="#storing-the-scraped-data">Storing the scraped data</a></li>
    <li><a href="#following-links">Following links</a></li>
    <li><a href="#a-shortcut-for-creating-requests">A shortcut for creating Requests</a></li>
    <li><a href="#more-examples-and-patterns">More examples and patterns</a></li>
    <li><a href="#using-spider-arguments">Using spider arguments</a></li>
    <li><a href="#next-steps">Next steps</a></li>
  </ol>
</nav>
                </div>
            </section>
        </aside>
    

        </div>
        <script 
                src="https://cdn.jsdelivr.net/npm/node-vibrant@3.1.5/dist/vibrant.min.js"integrity="sha256-5NovOZc4iwiAWTYIFiIM7DxKUXKWvpVEuMEPLzcm5/g="crossorigin="anonymous"
                defer="false"
                >
            </script><script type="text/javascript" src="/ts/main.js" defer></script>
<script>
    (function () {
        const customFont = document.createElement('link');
        customFont.href = "https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap";

        customFont.type = "text/css";
        customFont.rel = "stylesheet";

        document.head.appendChild(customFont);
    }());
</script>

    </body>
</html>
